{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QipCL4N-745s",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1767611167893,
     "user_tz": -420,
     "elapsed": 6285,
     "user": {
      "displayName": "Hải Lê Phước",
      "userId": "02688347978832676110"
     }
    },
    "outputId": "cde9b4e2-2bbe-4546-aab4-0f964a068620"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Using Colab cache for faster access to the 'person-segmentation' dataset.\n",
      "Using Colab cache for faster access to the 'supervisely-filtered-segmentation-person-dataset' dataset.\n",
      "Data source import complete.\n",
      "/kaggle/input/person-segmentation\n",
      "/kaggle/input/supervisely-filtered-segmentation-person-dataset\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import kagglehub\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "nikhilroxtomar_person_segmentation_path = kagglehub.dataset_download('nikhilroxtomar/person-segmentation')\n",
    "tapakah68_supervisely_filtered_segmentation_person_dataset_path = kagglehub.dataset_download('tapakah68/supervisely-filtered-segmentation-person-dataset')\n",
    "\n",
    "print('Data source import complete.')\n",
    "print(nikhilroxtomar_person_segmentation_path)\n",
    "print(tapakah68_supervisely_filtered_segmentation_person_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames[:1]:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXBk-4Co6Had",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1767611177122,
     "user_tz": -420,
     "elapsed": 9228,
     "user": {
      "displayName": "Hải Lê Phước",
      "userId": "02688347978832676110"
     }
    },
    "outputId": "481a7981-4ac0-477d-c6f7-6e991385ee92"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/kaggle/input/person-segmentation/people_segmentation/README\n",
      "/kaggle/input/person-segmentation/people_segmentation/segmentation/val.txt\n",
      "/kaggle/input/person-segmentation/people_segmentation/images/pexels-photo-219004.jpg\n",
      "/kaggle/input/person-segmentation/people_segmentation/masks/girl-beautiful-beautiful-girl-face.png\n",
      "/kaggle/input/supervisely-filtered-segmentation-person-dataset/df.csv\n",
      "/kaggle/input/supervisely-filtered-segmentation-person-dataset/supervisely_person_clean_2667_img/supervisely_person_clean_2667_img/collage/ds6_pexels-photo-792385.jpg\n",
      "/kaggle/input/supervisely-filtered-segmentation-person-dataset/supervisely_person_clean_2667_img/supervisely_person_clean_2667_img/images/ds8_pexels-photo-838817.png\n",
      "/kaggle/input/supervisely-filtered-segmentation-person-dataset/supervisely_person_clean_2667_img/supervisely_person_clean_2667_img/masks/ds8_pexels-photo-838817.png\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "images_path =  \"/kaggle/input/supervisely-filtered-segmentation-person-dataset/supervisely_person_clean_2667_img/supervisely_person_clean_2667_img/\"\n",
    "masks_path  = \"/kaggle/input/supervisely-filtered-segmentation-person-dataset/supervisely_person_clean_2667_img/supervisely_person_clean_2667_img/\"\n",
    "\n",
    "images_path2=\"/kaggle/input/person-segmentation/people_segmentation/images/\"\n",
    "masks_path2=\"/kaggle/input/person-segmentation/people_segmentation/masks/\"\n",
    "df =  pd.read_csv('/kaggle/input/supervisely-filtered-segmentation-person-dataset/df.csv')\n",
    "df.head()\n",
    "images_path2_list = sorted(os.listdir(images_path2))\n",
    "masks_path2_list = sorted(os.listdir(masks_path2))\n",
    "df2 = df[[\"images\", \"masks\"]].copy()\n",
    "df2[\"images\"] = df2['images'].apply(lambda x: images_path + x)\n",
    "df2[\"masks\"]  = df2['masks'].apply(lambda x: masks_path + x)\n",
    "df2[\"coef\"]   = 1\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    \"images\": [images_path2 + elt for elt in images_path2_list],\n",
    "    \"masks\":  [masks_path2 + elt for elt in masks_path2_list],\n",
    "    \"coef\":   255\n",
    "})\n",
    "\n",
    "final_df = pd.concat([df2, df3], ignore_index=True)\n",
    "\n",
    "X_train_raw, X_test_raw  =  train_test_split(final_df, test_size=0.1, random_state=42)"
   ],
   "metadata": {
    "id": "b36mwrGe-2Hz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1767611177154,
     "user_tz": -420,
     "elapsed": 31,
     "user": {
      "displayName": "Hải Lê Phước",
      "userId": "02688347978832676110"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "final_df = final_df.copy()\n",
    "final_df[\"source\"] = np.where(final_df[\"coef\"] == 1, \"supervisely\", \"person_seg\")\n",
    "print(\"Tổng số mẫu:\", len(final_df))\n",
    "print(\"\\nSố mẫu theo nguồn:\")\n",
    "print(final_df[\"source\"].value_counts())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EnWEsYb81BC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1767611177197,
     "user_tz": -420,
     "elapsed": 12,
     "user": {
      "displayName": "Hải Lê Phước",
      "userId": "02688347978832676110"
     }
    },
    "outputId": "e4fc3290-5124-4f49-9a95-27741d176bf3"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tổng số mẫu: 8345\n",
      "\n",
      "Số mẫu theo nguồn:\n",
      "source\n",
      "person_seg     5678\n",
      "supervisely    2667\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def dice_loss(logits, target, eps=1e-6):\n",
    "    pred = torch.sigmoid(logits)\n",
    "    target = target.float()\n",
    "\n",
    "    pred = pred.view(pred.size(0), -1)\n",
    "    target = target.view(target.size(0), -1)\n",
    "\n",
    "    inter = (pred * target).sum(dim=1)\n",
    "    denom = pred.sum(dim=1) + target.sum(dim=1)\n",
    "    dice = (2 * inter + eps) / (denom + eps)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "def dice_score_from_logits(logits, target, thr=0.5, eps=1e-6):\n",
    "    prob = torch.sigmoid(logits)\n",
    "    pred = (prob > thr).float()\n",
    "    inter = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    return ((2*inter + eps) / (union + eps)).item()\n",
    "\n",
    "def logits_to_probs_preds(logits, thr=0.5):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs > thr).float()\n",
    "    return probs, preds\n",
    "def update_global_stats_from_logits(logits, targets, thr=0.5):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs > thr).float()\n",
    "\n",
    "    tp = (preds * targets).sum().item()\n",
    "    fp = (preds * (1 - targets)).sum().item()\n",
    "    fn = ((1 - preds) * targets).sum().item()\n",
    "\n",
    "    correct = (preds == targets).float().sum().item()\n",
    "    total = targets.numel()\n",
    "\n",
    "    return tp, fp, fn, correct, total\n"
   ],
   "metadata": {
    "id": "82Fu2vwtGg59",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1767611177234,
     "user_tz": -420,
     "elapsed": 39,
     "user": {
      "displayName": "Hải Lê Phước",
      "userId": "02688347978832676110"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RawSegDataset(Dataset):\n",
    "    def __init__(self, df, size=512):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.size = size\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32).view(3,1,1)\n",
    "        self.std  = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32).view(3,1,1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        img_path  = row[\"images\"]\n",
    "        mask_path = row[\"masks\"]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        img = img.resize((self.size, self.size), Image.BILINEAR)\n",
    "        mask = mask.resize((self.size, self.size), Image.NEAREST)\n",
    "\n",
    "        img_np = np.array(img, dtype=np.float32)\n",
    "        mask_np = np.array(mask, dtype=np.float32)\n",
    "\n",
    "        max_val = mask_np.max() if mask_np.max() > 0 else 1.0\n",
    "        if max_val > 1.0:\n",
    "            mask_np = mask_np / max_val\n",
    "        mask_bin = (mask_np >= 0.5).astype(np.float32)\n",
    "\n",
    "        img_np = img_np / 255.0\n",
    "\n",
    "        img_t = torch.from_numpy(img_np).permute(2,0,1).float()\n",
    "        mask_t = torch.from_numpy(mask_bin).unsqueeze(0).float()\n",
    "\n",
    "        img_t = (img_t - self.mean) / self.std\n",
    "\n",
    "        return img_t, mask_t\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super().__init__()\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "            self.conv = DoubleConv(in_ch, out_ch)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size(2) - x1.size(2)\n",
    "        diffX = x2.size(3) - x1.size(3)\n",
    "        if diffY != 0 or diffX != 0:\n",
    "            x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1, base_c=64, bilinear=True):\n",
    "        super().__init__()\n",
    "        self.in_conv = DoubleConv(in_channels, base_c)\n",
    "        self.down1 = Down(base_c, base_c * 2)\n",
    "        self.down2 = Down(base_c * 2, base_c * 4)\n",
    "        self.down3 = Down(base_c * 4, base_c * 8)\n",
    "\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(base_c * 8, base_c * 16 // factor)\n",
    "\n",
    "        self.up1 = Up(base_c * 16, base_c * 8 // factor, bilinear=bilinear)\n",
    "        self.up2 = Up(base_c * 8, base_c * 4 // factor, bilinear=bilinear)\n",
    "        self.up3 = Up(base_c * 4, base_c * 2 // factor, bilinear=bilinear)\n",
    "        self.up4 = Up(base_c * 2, base_c, bilinear=bilinear)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(base_c, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.in_conv(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x,  x3)\n",
    "        x = self.up3(x,  x2)\n",
    "        x = self.up4(x,  x1)\n",
    "\n",
    "        logits = self.out_conv(x)\n",
    "        return logits"
   ],
   "metadata": {
    "id": "SUudODXPdE5x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_ds = RawSegDataset(X_train_raw, size=256)\n",
    "val_ds   = RawSegDataset(X_test_raw,  size=256)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_channels=3, num_classes=1, base_c=32, bilinear=True).to(device)\n",
    "\n",
    "criterion_bce = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 20\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_iou\": [],\n",
    "    \"val_dice\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"val_prec\": [],\n",
    "    \"val_recall\": [],\n",
    "    \"val_f1\": []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    tp = fp = fn = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, masks in tqdm(train_loader, desc=f\"Train epoch {epoch+1}\"):\n",
    "        imgs = imgs.to(device).float()\n",
    "        masks = masks.to(device).float()\n",
    "\n",
    "        logits = model(imgs)\n",
    "\n",
    "        bce = criterion_bce(logits, masks)\n",
    "        dsc = dice_loss(logits, masks)\n",
    "        loss = bce + dsc\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _tp, _fp, _fn, _correct, _total = update_global_stats_from_logits(logits, masks, thr=0.5)\n",
    "            tp += _tp\n",
    "            fp += _fp\n",
    "            fn += _fn\n",
    "            correct += _correct\n",
    "            total += _total\n",
    "\n",
    "    avg_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "    train_iou  = tp / (tp + fp + fn + 1e-6)\n",
    "    train_dice = (2*tp) / (2*tp + fp + fn + 1e-6)\n",
    "    train_acc  = correct / max(1, total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - train avg loss: {avg_loss:.4f} | IoU: {train_iou:.4f} | Dice: {train_dice:.4f} | Acc: {train_acc:.4f}\")\n",
    "    history[\"train_loss\"].append(avg_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "\n",
    "    v_tp = v_fp = v_fn = 0.0\n",
    "    v_correct = 0.0\n",
    "    v_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs = imgs.to(device).float()\n",
    "            masks = masks.to(device).float()\n",
    "\n",
    "            logits = model(imgs)\n",
    "\n",
    "            bce = criterion_bce(logits, masks)\n",
    "            dsc = dice_loss(logits, masks)\n",
    "            batch_loss = (bce + dsc).item()\n",
    "            val_loss += batch_loss\n",
    "            val_steps += 1\n",
    "\n",
    "            _tp, _fp, _fn, _correct, _total = update_global_stats_from_logits(logits, masks, thr=0.5)\n",
    "            v_tp += _tp\n",
    "            v_fp += _fp\n",
    "            v_fn += _fn\n",
    "            v_correct += _correct\n",
    "            v_total += _total\n",
    "\n",
    "    avg_val_loss = val_loss / max(1, val_steps)\n",
    "\n",
    "    val_iou  = v_tp / (v_tp + v_fp + v_fn + 1e-6)\n",
    "    val_dice = (2*v_tp) / (2*v_tp + v_fp + v_fn + 1e-6)\n",
    "    val_acc  = v_correct / max(1, v_total)\n",
    "\n",
    "    val_prec   = (v_tp + 1e-6) / (v_tp + v_fp + 1e-6)\n",
    "    val_recall = (v_tp + 1e-6) / (v_tp + v_fn + 1e-6)\n",
    "    val_f1     = (2*val_prec*val_recall + 1e-6) / (val_prec + val_recall + 1e-6)\n",
    "\n",
    "    history[\"val_loss\"].append(avg_val_loss)\n",
    "    history[\"val_iou\"].append(val_iou)\n",
    "    history[\"val_dice\"].append(val_dice)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "    history[\"val_prec\"].append(val_prec)\n",
    "    history[\"val_recall\"].append(val_recall)\n",
    "    history[\"val_f1\"].append(val_f1)\n",
    "\n",
    "    print(f\"Val loss: {avg_val_loss:.4f} | IoU: {val_iou:.4f} | Dice: {val_dice:.4f} | Acc: {val_acc:.4f}\")\n",
    "    print(f\"Precision: {val_prec:.4f} | Recall: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "hist_df = pd.DataFrame(history)\n",
    "hist_df.to_csv(\"/content/drive/MyDrive/Data Mining/Project/Model/training_unet_history_raw_metrics.csv\", index=False)\n",
    "print(\"Saved training history to Drive (training_unet_history_raw_metrics.csv)\")\n",
    "save_path = \"/content/drive/MyDrive/Data Mining/Project/Model/unet_raw.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, save_path)\n",
    "print(f\"Model saved to {save_path}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kt-QBOohArfP",
    "outputId": "9194aa30-c36d-469e-91a5-8720da9e3e9a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1767616545488,
     "user_tz": -420,
     "elapsed": 5018754,
     "user": {
      "displayName": "Hải Lê Phước",
      "userId": "02688347978832676110"
     }
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 1: 100%|██████████| 939/939 [03:55<00:00,  3.99it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 - train avg loss: 0.8513 | IoU: 0.5713 | Dice: 0.7271 | Acc: 0.8410\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.6778 | IoU: 0.6516 | Dice: 0.7890 | Acc: 0.8863\n",
      "Precision: 0.7966 | Recall: 0.7816 | F1: 0.7890\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 2: 100%|██████████| 939/939 [03:54<00:00,  4.00it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 - train avg loss: 0.6131 | IoU: 0.6694 | Dice: 0.8019 | Acc: 0.8890\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.5444 | IoU: 0.6758 | Dice: 0.8065 | Acc: 0.9034\n",
      "Precision: 0.8856 | Recall: 0.7404 | F1: 0.8065\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 3: 100%|██████████| 939/939 [03:49<00:00,  4.10it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3 - train avg loss: 0.5043 | IoU: 0.7172 | Dice: 0.8353 | Acc: 0.9085\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.4556 | IoU: 0.7329 | Dice: 0.8458 | Acc: 0.9174\n",
      "Precision: 0.8586 | Recall: 0.8335 | F1: 0.8458\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 4: 100%|██████████| 939/939 [03:48<00:00,  4.11it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4 - train avg loss: 0.4365 | IoU: 0.7516 | Dice: 0.8582 | Acc: 0.9215\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.4017 | IoU: 0.7668 | Dice: 0.8680 | Acc: 0.9254\n",
      "Precision: 0.8361 | Recall: 0.9024 | F1: 0.8680\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 5: 100%|██████████| 939/939 [03:48<00:00,  4.10it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5 - train avg loss: 0.3845 | IoU: 0.7808 | Dice: 0.8769 | Acc: 0.9318\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.3621 | IoU: 0.7859 | Dice: 0.8801 | Acc: 0.9354\n",
      "Precision: 0.8888 | Recall: 0.8715 | F1: 0.8801\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 6: 100%|██████████| 939/939 [03:47<00:00,  4.12it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6 - train avg loss: 0.3408 | IoU: 0.8040 | Dice: 0.8914 | Acc: 0.9398\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.3446 | IoU: 0.7975 | Dice: 0.8874 | Acc: 0.9384\n",
      "Precision: 0.8820 | Recall: 0.8928 | F1: 0.8874\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 7: 100%|██████████| 939/939 [03:47<00:00,  4.13it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7 - train avg loss: 0.3068 | IoU: 0.8233 | Dice: 0.9031 | Acc: 0.9463\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.3269 | IoU: 0.8110 | Dice: 0.8957 | Acc: 0.9413\n",
      "Precision: 0.8669 | Recall: 0.9264 | F1: 0.8957\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 8: 100%|██████████| 939/939 [03:50<00:00,  4.08it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8 - train avg loss: 0.2783 | IoU: 0.8398 | Dice: 0.9129 | Acc: 0.9518\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.3213 | IoU: 0.8055 | Dice: 0.8923 | Acc: 0.9430\n",
      "Precision: 0.9180 | Recall: 0.8680 | F1: 0.8923\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 9: 100%|██████████| 939/939 [03:52<00:00,  4.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9 - train avg loss: 0.2491 | IoU: 0.8572 | Dice: 0.9231 | Acc: 0.9574\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.3009 | IoU: 0.8239 | Dice: 0.9034 | Acc: 0.9484\n",
      "Precision: 0.9197 | Recall: 0.8877 | F1: 0.9034\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 10: 100%|██████████| 939/939 [03:48<00:00,  4.10it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10 - train avg loss: 0.2260 | IoU: 0.8696 | Dice: 0.9302 | Acc: 0.9614\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2754 | IoU: 0.8398 | Dice: 0.9129 | Acc: 0.9526\n",
      "Precision: 0.9128 | Recall: 0.9131 | F1: 0.9129\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 11: 100%|██████████| 939/939 [03:50<00:00,  4.08it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 11 - train avg loss: 0.2023 | IoU: 0.8835 | Dice: 0.9381 | Acc: 0.9658\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.3233 | IoU: 0.8143 | Dice: 0.8977 | Acc: 0.9468\n",
      "Precision: 0.9410 | Recall: 0.8582 | F1: 0.8977\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 12: 100%|██████████| 939/939 [03:47<00:00,  4.13it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 12 - train avg loss: 0.1830 | IoU: 0.8956 | Dice: 0.9449 | Acc: 0.9695\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2619 | IoU: 0.8497 | Dice: 0.9187 | Acc: 0.9556\n",
      "Precision: 0.9151 | Recall: 0.9224 | F1: 0.9187\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 13: 100%|██████████| 939/939 [03:49<00:00,  4.09it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 13 - train avg loss: 0.1731 | IoU: 0.9010 | Dice: 0.9479 | Acc: 0.9712\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.3032 | IoU: 0.8307 | Dice: 0.9075 | Acc: 0.9479\n",
      "Precision: 0.8770 | Recall: 0.9402 | F1: 0.9075\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 14: 100%|██████████| 939/939 [03:49<00:00,  4.09it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 14 - train avg loss: 0.1580 | IoU: 0.9107 | Dice: 0.9532 | Acc: 0.9741\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2535 | IoU: 0.8619 | Dice: 0.9258 | Acc: 0.9593\n",
      "Precision: 0.9179 | Recall: 0.9339 | F1: 0.9258\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 15: 100%|██████████| 939/939 [03:48<00:00,  4.11it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 15 - train avg loss: 0.1460 | IoU: 0.9169 | Dice: 0.9567 | Acc: 0.9760\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2513 | IoU: 0.8598 | Dice: 0.9246 | Acc: 0.9588\n",
      "Precision: 0.9200 | Recall: 0.9293 | F1: 0.9246\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 16: 100%|██████████| 939/939 [03:48<00:00,  4.12it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 16 - train avg loss: 0.1413 | IoU: 0.9192 | Dice: 0.9579 | Acc: 0.9767\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2872 | IoU: 0.8522 | Dice: 0.9202 | Acc: 0.9559\n",
      "Precision: 0.9062 | Recall: 0.9347 | F1: 0.9202\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 17: 100%|██████████| 939/939 [03:52<00:00,  4.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 17 - train avg loss: 0.1232 | IoU: 0.9301 | Dice: 0.9638 | Acc: 0.9800\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2461 | IoU: 0.8716 | Dice: 0.9314 | Acc: 0.9620\n",
      "Precision: 0.9148 | Recall: 0.9486 | F1: 0.9314\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 18: 100%|██████████| 939/939 [03:51<00:00,  4.05it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 18 - train avg loss: 0.1170 | IoU: 0.9334 | Dice: 0.9656 | Acc: 0.9810\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2865 | IoU: 0.8511 | Dice: 0.9195 | Acc: 0.9575\n",
      "Precision: 0.9487 | Recall: 0.8921 | F1: 0.9195\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 19: 100%|██████████| 939/939 [03:51<00:00,  4.06it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 19 - train avg loss: 0.1122 | IoU: 0.9364 | Dice: 0.9672 | Acc: 0.9819\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2460 | IoU: 0.8671 | Dice: 0.9288 | Acc: 0.9613\n",
      "Precision: 0.9296 | Recall: 0.9280 | F1: 0.9288\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train epoch 20: 100%|██████████| 939/939 [03:53<00:00,  4.03it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 20 - train avg loss: 0.1067 | IoU: 0.9391 | Dice: 0.9686 | Acc: 0.9827\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val loss: 0.2632 | IoU: 0.8600 | Dice: 0.9247 | Acc: 0.9588\n",
      "Precision: 0.9188 | Recall: 0.9308 | F1: 0.9247\n",
      "Saved training history to Drive (training_history_raw_metrics.csv)\n",
      "Model saved to /content/drive/MyDrive/Data Mining/Project/Model/unet_raw.pth\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1vj1MbRYgRGP0RRUJqS4UsRJ78wFcDYZ-",
     "timestamp": 1767588461868
    }
   ],
   "mount_file_id": "1vj1MbRYgRGP0RRUJqS4UsRJ78wFcDYZ-",
   "authorship_tag": "ABX9TyNPwy5xnrzw6eU7nwJLDimu"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
