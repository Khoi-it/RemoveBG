{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10149,"status":"ok","timestamp":1767684513667,"user":{"displayName":"Hải Lê Phước","userId":"11341395424994787343"},"user_tz":-420},"id":"EUx8GM6cBw6_","outputId":"5d9b64d0-a502-4c04-d2dd-2b6d74bb3dbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Using Colab cache for faster access to the 'person-segmentation' dataset.\n","Using Colab cache for faster access to the 'supervisely-filtered-segmentation-person-dataset' dataset.\n","Data source import complete.\n","/kaggle/input/person-segmentation\n","/kaggle/input/supervisely-filtered-segmentation-person-dataset\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import kagglehub\n","import os\n","from sklearn.model_selection import train_test_split\n","import random\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageOps\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import torchvision.transforms as T\n","import torchvision.transforms.functional as TF\n","from torchvision.transforms.functional import InterpolationMode\n","import torch.backends.cudnn as cudnn\n","from torch.cuda.amp import autocast, GradScaler\n","\n","nikhilroxtomar_person_segmentation_path = kagglehub.dataset_download('nikhilroxtomar/person-segmentation')\n","tapakah68_supervisely_filtered_segmentation_person_dataset_path = kagglehub.dataset_download('tapakah68/supervisely-filtered-segmentation-person-dataset')\n","\n","print('Data source import complete.')\n","print(nikhilroxtomar_person_segmentation_path)\n","print(tapakah68_supervisely_filtered_segmentation_person_dataset_path)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"FFKTGQ8iGY86","executionInfo":{"status":"ok","timestamp":1767684513703,"user_tz":-420,"elapsed":33,"user":{"displayName":"Hải Lê Phước","userId":"11341395424994787343"}}},"outputs":[],"source":["images_path =  \"/kaggle/input/supervisely-filtered-segmentation-person-dataset/supervisely_person_clean_2667_img/supervisely_person_clean_2667_img/\"\n","masks_path  = \"/kaggle/input/supervisely-filtered-segmentation-person-dataset/supervisely_person_clean_2667_img/supervisely_person_clean_2667_img/\"\n","\n","images_path2=\"/kaggle/input/person-segmentation/people_segmentation/images/\"\n","masks_path2=\"/kaggle/input/person-segmentation/people_segmentation/masks/\"\n","df =  pd.read_csv('/kaggle/input/supervisely-filtered-segmentation-person-dataset/df.csv')\n","df.head()\n","images_path2_list = sorted(os.listdir(images_path2))\n","masks_path2_list = sorted(os.listdir(masks_path2))\n","df2 = df[[\"images\", \"masks\"]].copy()\n","df2[\"images\"] = df2['images'].apply(lambda x: images_path + x)\n","df2[\"masks\"]  = df2['masks'].apply(lambda x: masks_path + x)\n","df2[\"coef\"]   = 1\n","\n","df3 = pd.DataFrame({\n","    \"images\": [images_path2 + elt for elt in images_path2_list],\n","    \"masks\":  [masks_path2 + elt for elt in masks_path2_list],\n","    \"coef\":   255\n","})\n","\n","final_df = pd.concat([df2, df3], ignore_index=True)\n","\n","X_train_raw, X_test_raw  =  train_test_split(final_df, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1767684513718,"user":{"displayName":"Hải Lê Phước","userId":"11341395424994787343"},"user_tz":-420},"id":"sls3PHwDvbg2","outputId":"4ae0062c-0607-4515-d580-7797f6caad6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tổng số mẫu: 8345\n","\n","Số mẫu theo nguồn:\n","source\n","person_seg     5678\n","supervisely    2667\n","Name: count, dtype: int64\n"]}],"source":["final_df = final_df.copy()\n","final_df[\"source\"] = np.where(final_df[\"coef\"] == 1, \"supervisely\", \"person_seg\")\n","print(\"Tổng số mẫu:\", len(final_df))\n","print(\"\\nSố mẫu theo nguồn:\")\n","print(final_df[\"source\"].value_counts())\n","\n","def dice_loss(logits, target, eps=1e-6):\n","    pred = torch.sigmoid(logits)\n","    target = target.float()\n","\n","    pred = pred.view(pred.size(0), -1)\n","    target = target.view(target.size(0), -1)\n","\n","    inter = (pred * target).sum(dim=1)\n","    denom = pred.sum(dim=1) + target.sum(dim=1)\n","    dice = (2 * inter + eps) / (denom + eps)\n","    return 1 - dice.mean()\n","\n","def dice_score_from_logits(logits, target, thr=0.5, eps=1e-6):\n","    prob = torch.sigmoid(logits)\n","    pred = (prob > thr).float()\n","    inter = (pred * target).sum()\n","    union = pred.sum() + target.sum()\n","    return ((2*inter + eps) / (union + eps)).item()\n","\n","def logits_to_probs_preds(logits, thr=0.5):\n","    probs = torch.sigmoid(logits)\n","    preds = (probs > thr).float()\n","    return probs, preds\n","def update_global_stats_from_logits(logits, targets, thr=0.5):\n","    \"\"\"\n","    logits: (B,1,H,W) raw logits\n","    targets: (B,1,H,W) {0,1}\n","    Return: tp, fp, fn, correct, total (all as python floats/ints)\n","    \"\"\"\n","    probs = torch.sigmoid(logits)\n","    preds = (probs > thr).float()\n","\n","    tp = (preds * targets).sum().item()\n","    fp = (preds * (1 - targets)).sum().item()\n","    fn = ((1 - preds) * targets).sum().item()\n","\n","    correct = (preds == targets).float().sum().item()\n","    total = targets.numel()\n","\n","    return tp, fp, fn, correct, total"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkj36cNatkiB","outputId":"b755c925-c805-43ce-cd51-bc834238e132","executionInfo":{"status":"ok","timestamp":1767690564254,"user_tz":-420,"elapsed":5682245,"user":{"displayName":"Hải Lê Phước","userId":"11341395424994787343"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Train epoch 1: 100%|██████████| 939/939 [04:46<00:00,  3.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 - train avg loss: 0.8880 | IoU: 0.5583 | Dice: 0.7166 | Acc: 0.8321\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.7262 | IoU: 0.6416 | Dice: 0.7817 | Acc: 0.8724\n","Precision: 0.7308 | Recall: 0.8402 | F1: 0.7817\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 2: 100%|██████████| 939/939 [04:24<00:00,  3.55it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 - train avg loss: 0.6557 | IoU: 0.6571 | Dice: 0.7930 | Acc: 0.8828\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.5384 | IoU: 0.7195 | Dice: 0.8368 | Acc: 0.9093\n","Precision: 0.8195 | Recall: 0.8549 | F1: 0.8368\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 3: 100%|██████████| 939/939 [04:17<00:00,  3.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 - train avg loss: 0.5420 | IoU: 0.7033 | Dice: 0.8258 | Acc: 0.9014\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.4480 | IoU: 0.7509 | Dice: 0.8578 | Acc: 0.9232\n","Precision: 0.8636 | Recall: 0.8520 | F1: 0.8578\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 4: 100%|██████████| 939/939 [04:19<00:00,  3.62it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 - train avg loss: 0.4743 | IoU: 0.7343 | Dice: 0.8468 | Acc: 0.9133\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.4047 | IoU: 0.7665 | Dice: 0.8678 | Acc: 0.9259\n","Precision: 0.8431 | Recall: 0.8940 | F1: 0.8678\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 5: 100%|██████████| 939/939 [04:18<00:00,  3.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 - train avg loss: 0.4257 | IoU: 0.7592 | Dice: 0.8631 | Acc: 0.9228\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.3720 | IoU: 0.7867 | Dice: 0.8806 | Acc: 0.9353\n","Precision: 0.8836 | Recall: 0.8777 | F1: 0.8806\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 6: 100%|██████████| 939/939 [04:16<00:00,  3.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 - train avg loss: 0.3897 | IoU: 0.7768 | Dice: 0.8744 | Acc: 0.9292\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.3578 | IoU: 0.7915 | Dice: 0.8836 | Acc: 0.9343\n","Precision: 0.8520 | Recall: 0.9177 | F1: 0.8836\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 7: 100%|██████████| 939/939 [04:18<00:00,  3.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 - train avg loss: 0.3742 | IoU: 0.7857 | Dice: 0.8800 | Acc: 0.9323\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.3337 | IoU: 0.8037 | Dice: 0.8912 | Acc: 0.9397\n","Precision: 0.8753 | Recall: 0.9076 | F1: 0.8912\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 8: 100%|██████████| 939/939 [04:18<00:00,  3.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 - train avg loss: 0.3465 | IoU: 0.8006 | Dice: 0.8893 | Acc: 0.9377\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.3331 | IoU: 0.7947 | Dice: 0.8856 | Acc: 0.9386\n","Precision: 0.8971 | Recall: 0.8744 | F1: 0.8856\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 9: 100%|██████████| 939/939 [04:23<00:00,  3.56it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 - train avg loss: 0.3360 | IoU: 0.8056 | Dice: 0.8923 | Acc: 0.9393\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.3041 | IoU: 0.8226 | Dice: 0.9027 | Acc: 0.9458\n","Precision: 0.8813 | Recall: 0.9252 | F1: 0.9027\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 10: 100%|██████████| 939/939 [04:23<00:00,  3.56it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 - train avg loss: 0.3190 | IoU: 0.8162 | Dice: 0.8988 | Acc: 0.9430\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.3086 | IoU: 0.8224 | Dice: 0.9026 | Acc: 0.9454\n","Precision: 0.8761 | Recall: 0.9306 | F1: 0.9026\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 11: 100%|██████████| 939/939 [04:27<00:00,  3.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 11 - train avg loss: 0.3089 | IoU: 0.8202 | Dice: 0.9012 | Acc: 0.9444\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2890 | IoU: 0.8255 | Dice: 0.9044 | Acc: 0.9482\n","Precision: 0.9078 | Recall: 0.9010 | F1: 0.9044\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 12: 100%|██████████| 939/939 [04:27<00:00,  3.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 12 - train avg loss: 0.2967 | IoU: 0.8289 | Dice: 0.9064 | Acc: 0.9472\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2746 | IoU: 0.8395 | Dice: 0.9128 | Acc: 0.9518\n","Precision: 0.8991 | Recall: 0.9268 | F1: 0.9128\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 13: 100%|██████████| 939/939 [04:28<00:00,  3.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 13 - train avg loss: 0.2863 | IoU: 0.8332 | Dice: 0.9090 | Acc: 0.9488\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2791 | IoU: 0.8322 | Dice: 0.9084 | Acc: 0.9478\n","Precision: 0.8686 | Recall: 0.9521 | F1: 0.9084\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 14: 100%|██████████| 939/939 [04:28<00:00,  3.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 14 - train avg loss: 0.2742 | IoU: 0.8409 | Dice: 0.9136 | Acc: 0.9514\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2672 | IoU: 0.8420 | Dice: 0.9142 | Acc: 0.9531\n","Precision: 0.9095 | Recall: 0.9190 | F1: 0.9142\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 15: 100%|██████████| 939/939 [04:20<00:00,  3.60it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 15 - train avg loss: 0.2655 | IoU: 0.8459 | Dice: 0.9165 | Acc: 0.9530\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2569 | IoU: 0.8454 | Dice: 0.9162 | Acc: 0.9539\n","Precision: 0.9062 | Recall: 0.9265 | F1: 0.9162\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 16: 100%|██████████| 939/939 [04:25<00:00,  3.53it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 16 - train avg loss: 0.2603 | IoU: 0.8486 | Dice: 0.9181 | Acc: 0.9539\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2675 | IoU: 0.8422 | Dice: 0.9144 | Acc: 0.9540\n","Precision: 0.9268 | Recall: 0.9022 | F1: 0.9144\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 17: 100%|██████████| 939/939 [04:27<00:00,  3.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 17 - train avg loss: 0.2503 | IoU: 0.8545 | Dice: 0.9216 | Acc: 0.9558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2530 | IoU: 0.8463 | Dice: 0.9167 | Acc: 0.9536\n","Precision: 0.8946 | Recall: 0.9400 | F1: 0.9167\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 18: 100%|██████████| 939/939 [04:26<00:00,  3.52it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 18 - train avg loss: 0.2433 | IoU: 0.8581 | Dice: 0.9236 | Acc: 0.9570\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2636 | IoU: 0.8491 | Dice: 0.9184 | Acc: 0.9543\n","Precision: 0.8931 | Recall: 0.9451 | F1: 0.9184\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 19: 100%|██████████| 939/939 [04:26<00:00,  3.53it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 19 - train avg loss: 0.2371 | IoU: 0.8614 | Dice: 0.9256 | Acc: 0.9581\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2508 | IoU: 0.8455 | Dice: 0.9163 | Acc: 0.9553\n","Precision: 0.9344 | Recall: 0.8989 | F1: 0.9163\n"]},{"output_type":"stream","name":"stderr","text":["Train epoch 20: 100%|██████████| 939/939 [04:29<00:00,  3.49it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 20 - train avg loss: 0.2321 | IoU: 0.8642 | Dice: 0.9271 | Acc: 0.9590\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.2297 | IoU: 0.8621 | Dice: 0.9259 | Acc: 0.9597\n","Precision: 0.9257 | Recall: 0.9262 | F1: 0.9259\n","Saved training history to Drive (training_unet_history_preprocessed_metrics.csv)\n","Model saved to /content/drive/MyDrive/Data Mining/Project/Model/unet_preprocessing.pth\n"]}],"source":["SEED = 42\n","\n","IMAGENET_MEAN = [0.485, 0.456, 0.406]\n","IMAGENET_STD  = [0.229, 0.224, 0.225]\n","import random, os\n","import numpy as np\n","import torch\n","\n","def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","def seed_worker(worker_id):\n","    # đảm bảo mỗi worker có seed khác nhau nhưng reproducible\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","\n","from torch.utils.data import Dataset\n","from PIL import Image, ImageOps\n","import torchvision.transforms as T\n","import torchvision.transforms.functional as TF\n","from torchvision.transforms import InterpolationMode\n","\n","# ====== GIỐNG RAW: thay mean/std theo RAW của bạn ======\n","RAW_MEAN = [0.485, 0.456, 0.406]  # <-- nếu raw khác, thay số ở đây\n","RAW_STD  = [0.229, 0.224, 0.225]  # <-- nếu raw khác, thay số ở đây\n","\n","class PreprocessedSegDataset(Dataset):\n","    def __init__(self, df, size=512, augment=False):\n","        self.df = df.reset_index(drop=True)\n","        self.size = size\n","        self.augment = augment\n","\n","        # tạo mean/std 1 lần (nhanh hơn)\n","        self.mean = torch.tensor(RAW_MEAN, dtype=torch.float32).view(3,1,1)\n","        self.std  = torch.tensor(RAW_STD,  dtype=torch.float32).view(3,1,1)\n","\n","        # augment giống kiểu bạn đang dùng\n","        self.color_jitter = T.ColorJitter(\n","            brightness=0.15, contrast=0.15, saturation=0.1, hue=0.02\n","        )\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _resize(self, img, mask):\n","        img  = img.resize((self.size, self.size), Image.BILINEAR)\n","        mask = mask.resize((self.size, self.size), Image.NEAREST)\n","        return img, mask\n","\n","    def _augment(self, img, mask):\n","        # Horizontal flip\n","        if random.random() < 0.5:\n","            img = ImageOps.mirror(img)\n","            mask = ImageOps.mirror(mask)\n","\n","        # small rotation\n","        if random.random() < 0.3:\n","            angle = random.uniform(-12, 12)\n","            img  = TF.rotate(img, angle, interpolation=InterpolationMode.BILINEAR, expand=False)\n","            mask = TF.rotate(mask, angle, interpolation=InterpolationMode.NEAREST, expand=False)\n","\n","        # random crop + resize (mild)\n","        if random.random() < 0.25:\n","            w, h = img.size\n","            scale = random.uniform(0.88, 1.0)\n","            new_w, new_h = int(w*scale), int(h*scale)\n","            left = random.randint(0, max(0, w-new_w))\n","            top  = random.randint(0, max(0, h-new_h))\n","            img  = img.crop((left, top, left+new_w, top+new_h))\n","            mask = mask.crop((left, top, left+new_w, top+new_h))\n","            img  = img.resize((self.size, self.size), Image.BILINEAR)\n","            mask = mask.resize((self.size, self.size), Image.NEAREST)\n","\n","        # color jitter chỉ áp cho ảnh\n","        img = self.color_jitter(img)\n","        return img, mask\n","\n","    def __getitem__(self, idx):\n","        row = self.df.loc[idx]\n","        img_path  = row[\"images\"]\n","        mask_path = row[\"masks\"]\n","\n","        img = Image.open(img_path).convert(\"RGB\")\n","        mask = Image.open(mask_path).convert(\"L\")\n","\n","        # resize trước (để batch shape cố định)\n","        img, mask = self._resize(img, mask)\n","\n","        # augment\n","        if self.augment:\n","            img, mask = self._augment(img, mask)\n","\n","        # to numpy\n","        img_np  = np.array(img, dtype=np.float32) / 255.0\n","        mask_np = np.array(mask, dtype=np.float32)\n","\n","        # ====== GIỐNG RAW: mask -> {0,1} robust ======\n","        max_val = mask_np.max() if mask_np.max() > 0 else 1.0\n","        if max_val > 1.0:\n","            mask_np = mask_np / max_val\n","        mask_np = (mask_np >= 0.5).astype(np.float32)\n","\n","        # to tensor\n","        img_t  = torch.from_numpy(img_np).permute(2,0,1).float()\n","        mask_t = torch.from_numpy(mask_np).unsqueeze(0).float()\n","\n","        # ====== GIỐNG RAW: normalize theo RAW mean/std ======\n","        img_t = (img_t - self.mean) / self.std\n","\n","        return img_t, mask_t\n","\n","\n","class DoubleConv(nn.Module):\n","    \"\"\"(Conv => BN => ReLU) * 2\"\"\"\n","    def __init__(self, in_ch, out_ch):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Down(nn.Module):\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\n","    def __init__(self, in_ch, out_ch):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_ch, out_ch)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Up(nn.Module):\n","    \"\"\"Upscaling then double conv (skip connections)\"\"\"\n","    def __init__(self, in_ch, out_ch, bilinear=True):\n","        super().__init__()\n","        self.bilinear = bilinear\n","\n","        if bilinear:\n","            # in_ch is concat channels (from skip + upsampled), we'll reduce inside DoubleConv\n","            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n","            self.conv = DoubleConv(in_ch, out_ch)\n","        else:\n","            # transposed conv halves channels\n","            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_ch, out_ch)\n","\n","    def forward(self, x1, x2):\n","        # x1: from decoder (lower res), x2: from encoder skip (higher res)\n","        x1 = self.up(x1)\n","\n","        # Pad if needed (in case of odd sizes)\n","        diffY = x2.size(2) - x1.size(2)\n","        diffX = x2.size(3) - x1.size(3)\n","        if diffY != 0 or diffX != 0:\n","            x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                            diffY // 2, diffY - diffY // 2])\n","\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels=3, num_classes=1, base_c=64, bilinear=True):\n","        super().__init__()\n","        self.in_conv = DoubleConv(in_channels, base_c)\n","        self.down1 = Down(base_c, base_c * 2)      # 64 -> 128\n","        self.down2 = Down(base_c * 2, base_c * 4)  # 128 -> 256\n","        self.down3 = Down(base_c * 4, base_c * 8)  # 256 -> 512\n","\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(base_c * 8, base_c * 16 // factor)  # 512 -> 1024 (or 512 if bilinear)\n","\n","        self.up1 = Up(base_c * 16, base_c * 8 // factor, bilinear=bilinear)\n","        self.up2 = Up(base_c * 8, base_c * 4 // factor, bilinear=bilinear)\n","        self.up3 = Up(base_c * 4, base_c * 2 // factor, bilinear=bilinear)\n","        self.up4 = Up(base_c * 2, base_c, bilinear=bilinear)\n","\n","        self.out_conv = nn.Conv2d(base_c, num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        x1 = self.in_conv(x)   # 512\n","        x2 = self.down1(x1)    # 256\n","        x3 = self.down2(x2)    # 128\n","        x4 = self.down3(x3)    # 64\n","        x5 = self.down4(x4)    # 32\n","\n","        x = self.up1(x5, x4)   # 64\n","        x = self.up2(x,  x3)   # 128\n","        x = self.up3(x,  x2)   # 256\n","        x = self.up4(x,  x1)   # 512\n","\n","        logits = self.out_conv(x)  # (B,1,H,W)\n","        return logits\n","\n","history_name = \"training_unet_history_preprocessed_metrics.csv\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = UNet(in_channels=3, num_classes=1, base_c=32, bilinear=True).to(device)\n","\n","criterion_bce = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","from torch.utils.data import DataLoader\n","\n","train_ds = PreprocessedSegDataset(X_train_raw, size=256, augment=True)\n","val_ds   = PreprocessedSegDataset(X_test_raw,  size=256, augment=False)\n","\n","g = torch.Generator()\n","g.manual_seed(SEED)\n","\n","train_loader = DataLoader(\n","    train_ds,\n","    batch_size=8,\n","    shuffle=True,\n","    num_workers=2,\n","    pin_memory=True,\n","    worker_init_fn=seed_worker,\n","    generator=g\n",")\n","\n","val_loader = DataLoader(\n","    val_ds,\n","    batch_size=8,\n","    shuffle=False,\n","    num_workers=2,\n","    pin_memory=True,\n","    worker_init_fn=seed_worker,\n","    generator=g\n",")\n","\n","\n","num_epochs = 20\n","history = {\n","    \"train_loss\": [],\n","    \"val_loss\": [],\n","    \"val_iou\": [],\n","    \"val_dice\": [],\n","    \"val_acc\": [],\n","    \"val_prec\": [],\n","    \"val_recall\": [],\n","    \"val_f1\": []\n","}\n","\n","for epoch in range(num_epochs):\n","    # ------------------ TRAIN ------------------\n","    model.train()\n","    running_loss = 0.0\n","\n","    # global accumulators\n","    tp = fp = fn = 0.0\n","    correct = 0.0\n","    total = 0\n","\n","    for imgs, masks in tqdm(train_loader, desc=f\"Train epoch {epoch+1}\"):\n","        imgs = imgs.to(device).float()\n","        masks = masks.to(device).float()\n","\n","        logits = model(imgs)\n","\n","        bce = criterion_bce(logits, masks)\n","        dsc = dice_loss(logits, masks)\n","        loss = bce + dsc\n","\n","        optimizer.zero_grad(set_to_none=True)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        with torch.no_grad():\n","            _tp, _fp, _fn, _correct, _total = update_global_stats_from_logits(logits, masks, thr=0.5)\n","            tp += _tp\n","            fp += _fp\n","            fn += _fn\n","            correct += _correct\n","            total += _total\n","\n","    avg_loss = running_loss / max(1, len(train_loader))\n","\n","    # global epoch metrics\n","    train_iou  = tp / (tp + fp + fn + 1e-6)\n","    train_dice = (2*tp) / (2*tp + fp + fn + 1e-6)\n","    train_acc  = correct / max(1, total)\n","\n","    print(f\"Epoch {epoch+1} - train avg loss: {avg_loss:.4f} | IoU: {train_iou:.4f} | Dice: {train_dice:.4f} | Acc: {train_acc:.4f}\")\n","    history[\"train_loss\"].append(avg_loss)\n","\n","    # ------------------ VAL ------------------\n","    model.eval()\n","    val_loss = 0.0\n","    val_steps = 0\n","\n","    # global accumulators for val\n","    v_tp = v_fp = v_fn = 0.0\n","    v_correct = 0.0\n","    v_total = 0\n","\n","    # global accumulators for precision/recall/f1\n","    # (they are derived from tp/fp/fn, so no need separate sums)\n","    with torch.no_grad():\n","        for imgs, masks in val_loader:\n","            imgs = imgs.to(device).float()\n","            masks = masks.to(device).float()\n","\n","            logits = model(imgs)\n","\n","            bce = criterion_bce(logits, masks)\n","            dsc = dice_loss(logits, masks)\n","            batch_loss = (bce + dsc).item()\n","            val_loss += batch_loss\n","            val_steps += 1\n","\n","            _tp, _fp, _fn, _correct, _total = update_global_stats_from_logits(logits, masks, thr=0.5)\n","            v_tp += _tp\n","            v_fp += _fp\n","            v_fn += _fn\n","            v_correct += _correct\n","            v_total += _total\n","\n","    avg_val_loss = val_loss / max(1, val_steps)\n","\n","    # global val metrics\n","    val_iou  = v_tp / (v_tp + v_fp + v_fn + 1e-6)\n","    val_dice = (2*v_tp) / (2*v_tp + v_fp + v_fn + 1e-6)\n","    val_acc  = v_correct / max(1, v_total)\n","\n","    val_prec   = (v_tp + 1e-6) / (v_tp + v_fp + 1e-6)\n","    val_recall = (v_tp + 1e-6) / (v_tp + v_fn + 1e-6)\n","    val_f1     = (2*val_prec*val_recall + 1e-6) / (val_prec + val_recall + 1e-6)\n","\n","    history[\"val_loss\"].append(avg_val_loss)\n","    history[\"val_iou\"].append(val_iou)\n","    history[\"val_dice\"].append(val_dice)\n","    history[\"val_acc\"].append(val_acc)\n","    history[\"val_prec\"].append(val_prec)\n","    history[\"val_recall\"].append(val_recall)\n","    history[\"val_f1\"].append(val_f1)\n","\n","    print(f\"Val loss: {avg_val_loss:.4f} | IoU: {val_iou:.4f} | Dice: {val_dice:.4f} | Acc: {val_acc:.4f}\")\n","    print(f\"Precision: {val_prec:.4f} | Recall: {val_recall:.4f} | F1: {val_f1:.4f}\")\n","\n","# save history\n","hist_df = pd.DataFrame(history)\n","out_path = f\"/content/drive/MyDrive/Data Mining/Project/Model/{history_name}\"\n","os.makedirs(os.path.dirname(out_path), exist_ok=True)\n","hist_df.to_csv(out_path, index=False)\n","print(f\"Saved training history to Drive ({history_name})\")\n","save_path = \"/content/drive/MyDrive/Data Mining/Project/Model/unet_preprocessing.pth\"\n","\n","torch.save({\n","    'model_state_dict': model.state_dict(),\n","    'optimizer_state_dict': optimizer.state_dict(),\n","}, save_path)\n","\n","print(f\"Model saved to {save_path}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1uXI2XPr5Mu1tAkzrchIDZRypjr5fsGxy","timestamp":1767588881365}],"authorship_tag":"ABX9TyMFrT2E7hXv1vSIgQW41mkC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}